
[{"content":"","date":"2 December 2024","externalUrl":null,"permalink":"/","section":"Akhil Kumar","summary":"","title":"Akhil Kumar","type":"page"},{"content":"","date":"2 December 2024","externalUrl":null,"permalink":"/tags/example/","section":"Tags","summary":"","title":"Example","type":"tags"},{"content":"Check out FabGPT, a new model designed to solve complex wafer defect knowledge queries in the semiconductor industry. LMMs, these powerful tools, have been used for various tasks, like image and text understanding. FabGPT uses LMMs to automatically spot tiny defects under tricky wafer backgrounds by matching enhanced multimodal features. This new approach cuts down on the need for manual settings and speeds up defect detection processes a lot.\nHere are some of FabGPT‚Äôs cool features:\nMultimodal Feature Enhancement: FabGPT uses a special technique to capture all the tiny details of both visual and textual information, making it super accurate at detecting defects. Efficient Query-Guided Attention: FabGPT has a special way of focusing on the parts of the wafer image that are most important based on the query, which helps it find defects that match the query criteria. Big Training Data: FabGPT was trained on a huge dataset of wafer images and defect descriptions, and then it was fine-tuned on a smaller dataset of complex defect scenarios. This comprehensive training makes it really good at generalizing and staying strong. FabGPT could be used for a bunch of cool things, like:\nAutomated Defect Classification: It can accurately categorize defects based on their visual features and descriptions. Root Cause Analysis: It can figure out why defects happen by looking at historical data and expert knowledge. Predictive Maintenance: It can predict when equipment might break down or when processes might go wrong by watching wafer defect trends. With FabGPT, wafer defect analysis is way easier and more accurate, which could totally change the game in the semiconductor industry!\n","date":"2 December 2024","externalUrl":null,"permalink":"/projects/1733165840736-fab-gpt-%EF%B8%8F/","section":"Projects","summary":"","title":"FAB-GPT üò∂‚Äçüå´Ô∏è","type":"projects"},{"content":"","date":"2 December 2024","externalUrl":null,"permalink":"/projects/","section":"Projects","summary":"","title":"Projects","type":"projects"},{"content":"","date":"2 December 2024","externalUrl":null,"permalink":"/tags/tag/","section":"Tags","summary":"","title":"Tag","type":"tags"},{"content":"","date":"2 December 2024","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":" Actor - Critic Method # Combination of\nActor : Responsible for selecting actions in ana environment Critic : Estimates the Value function\nAC methods update both the actor (policy parameters) and critic (value function parameters) 1.¬†Advantage Actor-Critic (A2C) # Uses a single neural network for both actor and critic. Employs a shared feature extractor for efficiency 2.¬†Deep Deterministic Policy Gradient (DDPG) # Designed for continuous action spaces. Utilizes a deterministic policy (actor) and a critic to estimate the action-value function. 3.¬†Proximal Policy Optimization (PPO) with Critic # A model-free, on-policy algorithm with a trust region method. Can be combined with a critic for improved stability. ","date":"30 November 2024","externalUrl":null,"permalink":"/projects/1732997246398-actor-critic-method--/","section":"Projects","summary":"","title":"Actor-Critic Method  üï¥","type":"projects"},{"content":" Diffusion-based Imitation Learning (DIL) # Which combines ideas from generative diffusion models and imitation learning. This is not a full implementation but a conceptual framework that captures the essential components.\nYes ! # Assume we have expert trajectories D = [(s_i, a_i)] # Step 1: Forward Diffusion Process (Add noise to expert trajectory) def forward_diffusion(x_0, timesteps): x_t = x_0 for t in range(1, timesteps + 1): noise = sample_noise(x_t.shape) x_t = apply_diffusion_step(x_t, noise, t) return x_t # Step 2: Train Reverse Diffusion Model def train_diffusion_model(trajectories, timesteps): for epoch in range(num_epochs): for x_0 in trajectories: # Each trajectory (expert demo) x_t = forward_diffusion(x_0, timesteps) for t in range(timesteps, 0, -1): predicted_x_t_1 = reverse_diffusion_step(x_t, t) # Model prediction loss = compute_loss(predicted_x_t_1, x_0) # Denoising score matching loss optimizer.step(loss) # Step 3: Sample from Reverse Diffusion Model (Imitate Expert) def sample_from_model(noise, timesteps): x_t = noise for t in range(timesteps, 0, -1): x_t = reverse_diffusion_step(x_t, t) # Generate trajectory return x_t # Final imitation trajectory üõ•Ô∏è Here is more from NVIDIA https://nturobotlearninglab.github.io/DRAIL/\n","date":"30 November 2024","externalUrl":null,"permalink":"/projects/1732973972627-diffusion-based-imitation-learning-/","section":"Projects","summary":"","title":"Diffusion Based Imitation Learning ü¶å","type":"projects"},{"content":"","date":"30 November 2024","externalUrl":null,"permalink":"/tags/imitation-learning/","section":"Tags","summary":"","title":"Imitation Learning","type":"tags"},{"content":" Imitation-Learning Wafer Fab # In this Notebook is a demo for the imitation learning that learns the pattern to mark some cells \u0026lsquo;x\u0026rsquo; for a semiconductor Wafer dataset , and then mimic the the pattern of the agent to an unseen dataset\nThe ImitationLearningCSV class is a versatile tool for human-in-the-loop machine learning. It enables users to interact with a CSV file, marking and unmarking specific cells. These human-provided annotations serve as valuable training data for a machine learning model. By learning from these expert-provided labels, the model can acquire the ability to predict future markings on similar data.\nThe class streamlines this process by:\nLoading Data: The load_existing_data method seamlessly reads the CSV file into a structured format, making it accessible for further analysis. Marking and Unmarking: The mark_cell and unmark_cell methods allow users to easily designate cells as important or unimportant, providing explicit guidance to the model. Feature Extraction: The extract_features method extracts relevant features from the marked cells, transforming them into a numerical representation that the machine learning model can understand. Data Preparation: The class prepares the extracted features and corresponding labels into a suitable format for training a machine learning model. By automating these steps, the ImitationLearningCSV class significantly simplifies the process of building imitation learning models, making it more accessible to a wider range of users.\nThe data is related to MFCs from the Semiconductor Manufacturing tools , and the Lalels for the Aliases are to be Marked by the Agent,\nCheck out the sample code on git. üëáüèª akhil4674/Imitation-Learning In this Notebook is a demo for the imitation learning that learns the pattern to mark some cells \u0026lsquo;x\u0026rsquo; for a semiconductor Wafer dataset , and then mimic the the pattern of the agent to an unseen dataset Jupyter Notebook 0 0 ","date":"30 November 2024","externalUrl":null,"permalink":"/projects/1732999247436-imitation-learning-/","section":"Projects","summary":"","title":"Imitation Learning üßèüèª‚Äç","type":"projects"},{"content":"","date":"30 November 2024","externalUrl":null,"permalink":"/tags/wafer-fab/","section":"Tags","summary":"","title":"Wafer Fab","type":"tags"},{"content":"","date":"29 November 2024","externalUrl":null,"permalink":"/about-me/","section":"About Mes","summary":"","title":"About Mes","type":"about-me"},{"content":" Analog Optical Computing: A Deep Dive ü§ø # Analog optical computing leverages the properties of light to perform calculations. Unlike digital computers, which rely on binary digits (bits) to represent information, analog optical computers utilize continuous values to represent data, much like how our brains process information.\nKey Components and Principles: üîë # Light Sources: Lasers or light-emitting diodes (LEDs) generate light beams. # Optical Components: These include lenses, mirrors, and optical fibers to manipulate and guide light. Light Detectors: Devices like photodetectors convert light signals back into electrical signals for further processing or output. How it Works:\nLight as Information Carrier: Light can be modulated in various ways, such as intensity, phase, or polarization, to represent data. üìä # Parallel Processing: Light can be split into multiple beams, allowing for parallel computations, significantly increasing processing speed. Nonlinear Optics: Nonlinear optical materials can manipulate light in ways that enable complex calculations, such as matrix multiplication and neural network operations. Advantages of Analog Optical Computing:\nHigh Speed: Light travels much faster than electrons, enabling rapid computations. üèéÔ∏è # Parallel Processing: The ability to process multiple operations simultaneously. Low Power Consumption: Optical components can be highly energy-efficient. Potential for High Density: Compact optical circuits can be densely packed. Challenges and Limitations:\nNoise and Interference: Light signals can be susceptible to noise and interference, which can degrade accuracy. üéØ # Complexity of Optical Components: Designing and manufacturing complex optical systems can be challenging. Integration with Electronics: Seamless integration of optical and electronic components is essential for practical applications. Recent Advancements and Future Potential:\nMicrosoft\u0026rsquo;s Analog Optical Computer: Microsoft has developed an analog optical computer capable of solving optimization problems. # Optical Neural Networks: Researchers are exploring the use of optical components to implement neural networks, potentially leading to faster and more energy-efficient AI systems. Optical Computing for Machine Learning: Optical computing can accelerate machine learning tasks, such as image and speech recognition\nPhoto by [Microsoft] üí° Wanna read more about it ?\nhttps://arxiv.org/abs/2301.11760\n","date":"29 November 2024","externalUrl":null,"permalink":"/projects/1732924668126-analog-optical-computing--ever-heard-of-it--%EF%B8%8F/","section":"Projects","summary":"","title":"Analog Optical Computing , Ever Heard of it ? ‚ö°Ô∏è","type":"projects"},{"content":"an example to get you started\nThis is a heading # This is a subheading # This is a subsubheading # This is a subsubsubheading # This is a paragraph with bold and italic text. Check more at Blowfish documentation undefined\n","date":"29 November 2024","externalUrl":null,"permalink":"/imitation-learning-/1732917446940-do-you-know-about-diffusion-based-imitation-learning-/","section":"Imitation Learning üëâüèªS","summary":"","title":"Do you know about Diffusion based Imitation Learning ","type":"imitation-learning-üëâüèª"},{"content":" About Me üèéÔ∏è My name is Akhil, and I‚Äôm currently an intern at Bosch in Semiconductor Fab, Process Engineering . I am currently pursuing my ** Master's degree in Sensor Systems Technology ** at Karlsruhe University of Applied Sciences. I come from electronics engineering background , I work with Machine Learning fusioned with Semiconductor World ü•Ω . Education Karlsruhe University of Applied Sciences Master\u0026#39;s in Sensor Systems Technology My degree program deals with the Fabrican , Working Mechanism , Programming and Development of Sensors used Industry-wide like Automotive üèéÔ∏è , Chemical Industry üß™, Biomedical Industry üß´ , and ofcourse Electrical Industry üîå. Education Gautam Buddha University Bachelors \u0026#43; Masters in VLSI (Very Large Scale Integrated Circuit) Design In my Integrated Bachelors and Masters degree , which was of 5 years combined , I learned the Basics of the Electronics engineering , and the Studies about Fabricating Chips üë®üèª‚Äçüíª , Designing the Architechure , Working with the related programming Work Experience üë®üèª‚Äçüíª Robert Bosch GmbH Intern I‚Äôm working with semiconductor with focus in MEMS technology. I currently work at Bosch Semiconductor WaferFab,ü§ñ where I‚Äôm in charge of monitoring and building processes strategies for CVD, PECVD, and SACVD tools from AMAT. These tools are important for producing MEMS gyroscopes and accelerometers. I‚Äôve got a deep understanding of how these processes work, how the tools works, and the whole workflow in a wafer fab. At Bosch Semiconductor Plant, whee I use the Data Analytics to monitor and control the Manufacturing Processes bringing the production quality till 3 sigma Value using Machine-learning Methods like Policy Optimization. Work Experience ü§ñ Autonomous Learning Robots - KIT Research Assistant Early this year I have joined his other Research Department the Autonomous Learning Robots (ALR) Lab at the¬†Institute for Anthropomatics and Robotics¬†of the¬†Department of Informatics¬†which focuses on the development of novel machine learning methods for robotics learning¬†like Reinforcement Learning and Policy Search also other areas like Imitation Learning and Interactive Learning .¬†I also worked on the management side there , like Managing Machine Learning Servers , Setting up machine new Servers üìÄ Work Experience ü¶æ FZI Forschungszentrum Informatik Research Assistant For almost past one year I have with working with Prof. Gerhard Neumann , First at FZI Forschungszentrum Informatik , where my focus was on developing and working with algorithms for Animal robot (Spot by Boston Dynamics)¬†which required correcting and reasoning the behaviour of the robots control arm and positions Based on Machine learning Algorithms. There I learned ROS Robot Operating System , and also focused on developing GUI page for the robot control ","date":"29 November 2024","externalUrl":null,"permalink":"/about-me/1732923295861-sooo..-what-do-you-want-to-know--/","section":"About Mes","summary":"","title":"Get to Know/ Kennlernen üëÄ","type":"about-me"},{"content":"","date":"29 November 2024","externalUrl":null,"permalink":"/imitation-learning-/","section":"Imitation Learning üëâüèªS","summary":"","title":"Imitation Learning üëâüèªS","type":"imitation-learning-üëâüèª"},{"content":" My research about it # This code implements the Proximal Policy Optimization (PPO) algorithm using TensorFlow and NumPy. PPO is a reinforcement learning algorithm used to train agents to make decisions in an environment.\nImportant Classes:\nPolicyNetwork: This class defines the neural network architecture used by the agent to decide which action to take given a state. It consists of two dense layers with ReLU activation and an output layer with softmax activation to produce action probabilities. PPO: This class implements the core logic of the PPO algorithm. It handles action selection, training the policy network, and updating the agent\u0026rsquo;s behavior. Important Functions:\nPolicyNetwork.__init__: Initializes the policy network with its layers. PolicyNetwork.call: Defines the forward pass of the network, taking a state as input and returning action probabilities. PPO.__init__: Initializes the PPO algorithm with hyperparameters like learning rate, clip ratio, and coefficients for value and entropy. PPO.get_action: Uses the policy network to select an action based on the current state. PPO.train: Updates the policy network\u0026rsquo;s weights based on collected experience (states, actions, advantages, returns, and old action probabilities) using gradient descent and the PPO objective function. This function is the core of the training process. akhil4674/Proximal-Policy-Optimization A model-free, on-policy algorithm with a trust region method. Can be combined with a critic for improved stability in policy search optimization. Python 0 0 ","date":"29 November 2024","externalUrl":null,"permalink":"/projects/1732918143002-my-interests-about-proximal-policy-optimization-ppo-/","section":"Projects","summary":"","title":"My Interests about Proximal Policy Optimization (PPO) ‚úÖ ","type":"projects"},{"content":" Fine Tuning the Algorithm Find an optimal policy for an agent to follow in order to maximize its cumulative reward.\nThis method involves searching through a space of possible policies, which are mappings from states to actions, in order to find the policy that yields the highest expected reward Like Gradient Descent and Evolutionary Algorithms üèÉüèª Evolutionary Algo Class of optimization algorithms inspired by the natural selection and evolution. They mimic the process of natural selection, reproduction and mutation\nTypes of Evolutionary Algos # 1. Genetic Algorithms (GA): These algorithms use a population of candidate solutions, which are represented as strings of symbols, and apply genetic operators such as selection, crossover, and mutation to evolve the population towards better solutions.\nEvolution Strategies (ES): ES algorithms optimize a population of candidate solutions by perturbing the current solutions with random noise and selecting the best-performing individuals for the next generation.\nGenetic Programming (GP): GP algorithms evolve computer programs or mathematical expressions to solve problems by using genetic operators to create and modify the structure of the programs.\nDifferential Evolution (DE): DE algorithms optimize a population of candidate solutions by using the difference between individuals in the population to guide the search towards better solutions.\ngraph LR; A[Lemons]--\u003eB[Lemonade]; B--\u003eC[Profit] ","date":"29 November 2024","externalUrl":null,"permalink":"/projects/1732916517379-policy-search-algorithms--/","section":"Projects","summary":"","title":"Policy-Search Algorithms üß† ","type":"projects"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]